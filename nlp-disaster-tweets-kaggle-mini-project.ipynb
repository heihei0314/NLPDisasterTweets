{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-04-27T08:54:01.312218Z","iopub.execute_input":"2023-04-27T08:54:01.313069Z","iopub.status.idle":"2023-04-27T08:54:01.322986Z","shell.execute_reply.started":"2023-04-27T08:54:01.313015Z","shell.execute_reply":"2023-04-27T08:54:01.322020Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1. Problem Statement\n\n>### The project is aimed to identified person's words in Twitter whethler announcing disaster. It is going to use RNN with LSTM to train and predict the data.\n>### There are 7613 entires in training data with three key attributes, \"keyword\", \"location\" and \"text\". The \"keyword\" and \"location could be null. The \"target\" denotes whether a tweet is about a real disaster (1) or not (0). 4342 are not disaster and 3271 are real. Since the test set is not labeled. 20% training set will be selected for validation.","metadata":{}},{"cell_type":"code","source":"dir_test = '/kaggle/input/nlp-getting-started/test/'\ndir_train = '/kaggle/input/nlp-getting-started/train/'\ntext_test = pd.read_csv('/kaggle/input/nlp-getting-started/test.csv')\ntext_train = pd.read_csv('/kaggle/input/nlp-getting-started/train.csv')\nprint(text_train.count())\nprint(text_train['target'].value_counts())\nplt.hist(text_train['target'])","metadata":{"execution":{"iopub.status.busy":"2023-04-27T08:54:01.324484Z","iopub.execute_input":"2023-04-27T08:54:01.325126Z","iopub.status.idle":"2023-04-27T08:54:01.608308Z","shell.execute_reply.started":"2023-04-27T08:54:01.325084Z","shell.execute_reply":"2023-04-27T08:54:01.607103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Exploratory Data Analysis (EDA) \n> ### We could find most of the words in \"text\" are meaningless stopwords. It might affect the training and anaylsis. Hence, it is going to dropout the stopwords. In addition, assuming that \"location\" is irrelavant. This colummn would be dropouted as well. Meanwhile, the \"keyword\" is added at the beginning of the \"text\", for convenient.","metadata":{}},{"cell_type":"code","source":"import seaborn as sns\ndef wordCourtBar(dataSet, index):\n    text_counts = dataSet[index].str.findall(r\"(\\w+)\").explode().value_counts()[:20]\n    print(text_counts)\n    text_counts.plot(kind='barh')\n\nwordCourtBar(text_train,'text')","metadata":{"execution":{"iopub.status.busy":"2023-04-27T08:54:01.610202Z","iopub.execute_input":"2023-04-27T08:54:01.610589Z","iopub.status.idle":"2023-04-27T08:54:02.399440Z","shell.execute_reply.started":"2023-04-27T08:54:01.610549Z","shell.execute_reply":"2023-04-27T08:54:02.398223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wordCourtBar(text_train,'keyword')","metadata":{"execution":{"iopub.status.busy":"2023-04-27T08:54:02.403455Z","iopub.execute_input":"2023-04-27T08:54:02.403772Z","iopub.status.idle":"2023-04-27T08:54:02.724336Z","shell.execute_reply.started":"2023-04-27T08:54:02.403742Z","shell.execute_reply":"2023-04-27T08:54:02.723219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#cleaning data\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nstop_words = stopwords.words('english')\nstop_words.extend(['t', 'co', 'I', 's', '#', 'A', '2', 'The', 'Ã›_', 'n', 'In', 'nan', 'http', 'https'])\nstop_words = set(stop_words) - set(['no', 'not'])\n\ndef dataCleaning(text):\n    word_tokens = word_tokenize(text)\n    filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]\n    #with no lower case conversion\n    filtered_sentence = []\n  \n    for w in word_tokens:\n        if w not in stop_words:\n            filtered_sentence.append(w)\n    return filtered_sentence\n\ntext_train['joint'] = text_train['keyword'].astype(str) + \" \"+text_train['text']\ntext_test['joint'] = text_test['keyword'].astype(str) + \" \"+text_test['text']\ntext_train['clean'] = text_train['joint'].apply(dataCleaning)\ntext_test['clean'] = text_test['joint'].apply(dataCleaning)\ntext_train['clean'] = text_train['clean'].apply(lambda x: \" \".join(x))\ntext_test['clean'] = text_test['clean'].apply(lambda x: \" \".join(x))\n\ntext_train.head()","metadata":{"execution":{"iopub.status.busy":"2023-04-27T08:54:02.726138Z","iopub.execute_input":"2023-04-27T08:54:02.726840Z","iopub.status.idle":"2023-04-27T08:54:05.213275Z","shell.execute_reply.started":"2023-04-27T08:54:02.726798Z","shell.execute_reply":"2023-04-27T08:54:05.212110Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> ### After cleaning the words (except the negative words \"no\", \"not\"), we could find some different wordings between real disaster and non-disaster entries in both text and keyword column.","metadata":{}},{"cell_type":"code","source":"T = text_train[text_train['target'] == 1]\nF = text_train[text_train['target'] == 0]\nwordCourtBar(T,'clean')","metadata":{"execution":{"iopub.status.busy":"2023-04-27T08:54:05.214859Z","iopub.execute_input":"2023-04-27T08:54:05.215504Z","iopub.status.idle":"2023-04-27T08:54:05.678069Z","shell.execute_reply.started":"2023-04-27T08:54:05.215464Z","shell.execute_reply":"2023-04-27T08:54:05.676909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wordCourtBar(F,'clean')","metadata":{"execution":{"iopub.status.busy":"2023-04-27T08:54:05.682280Z","iopub.execute_input":"2023-04-27T08:54:05.683567Z","iopub.status.idle":"2023-04-27T08:54:06.089992Z","shell.execute_reply.started":"2023-04-27T08:54:05.683514Z","shell.execute_reply":"2023-04-27T08:54:06.088586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(8, 72), dpi=100)\nsns.countplot(y=text_train.sort_values(by='target', ascending=False)['keyword'],\n              hue=text_train.sort_values(by='target', ascending=False)['target'])\nplt.tick_params(axis='x', labelsize=15)\nplt.tick_params(axis='y', labelsize=12)\nplt.legend(loc=1)\nplt.title('Target Distribution in Keywords')\n\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-04-27T08:54:06.092005Z","iopub.execute_input":"2023-04-27T08:54:06.093047Z","iopub.status.idle":"2023-04-27T08:54:09.897864Z","shell.execute_reply.started":"2023-04-27T08:54:06.093005Z","shell.execute_reply":"2023-04-27T08:54:09.896876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Model Architecture \n> ### Consider the correlation between text and its sequency. A LSTM model is going to be used\n> ### In the first model \nLSTM unit is set to 4. tanh is going to be used as activation functions for the output layer. \n\n> ### In the second model \nLSTM unit is set to 256. tanh is going to be used as activation functions for the output layer. Normalization is used.","metadata":{"execution":{"iopub.status.busy":"2023-04-27T06:57:35.153135Z","iopub.execute_input":"2023-04-27T06:57:35.153513Z","iopub.status.idle":"2023-04-27T06:57:35.160724Z","shell.execute_reply.started":"2023-04-27T06:57:35.153478Z","shell.execute_reply":"2023-04-27T06:57:35.159039Z"}}},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.text import one_hot, Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\ndef word_count(str):\n    words = str.split()\n    counts = len(words)\n    return counts\n\ntext_train['wordTotal'] = text_train['clean'].apply(word_count)\ntotal_words_train = max(text_train['wordTotal'])\ntokenizer = Tokenizer(num_words = total_words_train)\ntokenizer.fit_on_texts(text_train['clean'])\ntrain_sequences = tokenizer.texts_to_sequences(text_train['clean'])\npadded_train = pad_sequences(train_sequences,maxlen = 40, padding = 'post', truncating = 'post')\n\ny_train = np.asarray(text_train['target'])","metadata":{"execution":{"iopub.status.busy":"2023-04-27T08:54:09.898952Z","iopub.execute_input":"2023-04-27T08:54:09.899325Z","iopub.status.idle":"2023-04-27T08:54:13.216159Z","shell.execute_reply.started":"2023-04-27T08:54:09.899285Z","shell.execute_reply":"2023-04-27T08:54:13.214975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import keras\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.optimizers import RMSprop\nbatchSize = 128 \nvalidationSplit = 0.2 \nepochs = 100\n\nmodel1 = keras.Sequential()\nmodel1.add(layers.Embedding(input_dim=total_words_train, output_dim=40))\nmodel1.add(layers.LSTM(4))\nmodel1.add(layers.Dense(4))\nmodel1.add(layers.Dense(1, activation='tanh'))\n\nmodel1.build()\nmodel1.summary()\nopt = RMSprop(learning_rate=0.01)\nmodel1.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\ny_train = np.asarray(text_train['target'])\nhist1 = model1.fit(padded_train, y_train, batch_size = batchSize, validation_split = validationSplit, epochs = epochs)","metadata":{"execution":{"iopub.status.busy":"2023-04-27T08:54:13.217781Z","iopub.execute_input":"2023-04-27T08:54:13.219220Z","iopub.status.idle":"2023-04-27T08:55:40.620977Z","shell.execute_reply.started":"2023-04-27T08:54:13.219178Z","shell.execute_reply":"2023-04-27T08:55:40.619656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model2 = keras.Sequential()\nmodel2.add(layers.Embedding(input_dim=total_words_train, output_dim=40))\nmodel2.add(layers.LSTM(256))\nmodel2.add(layers.Dense(256))\nmodel2.add(layers.BatchNormalization())\nmodel2.add(layers.Dense(1, activation='tanh'))\n\nmodel2.build()\nmodel2.summary()\nopt = RMSprop(learning_rate=0.01)\nmodel2.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\nhist2 = model2.fit(padded_train, y_train, batch_size = batchSize, validation_split = validationSplit, epochs = epochs)","metadata":{"execution":{"iopub.status.busy":"2023-04-27T08:55:40.623329Z","iopub.execute_input":"2023-04-27T08:55:40.624008Z","iopub.status.idle":"2023-04-27T08:57:04.978455Z","shell.execute_reply.started":"2023-04-27T08:55:40.623963Z","shell.execute_reply":"2023-04-27T08:57:04.977120Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. Results and Analysis \n\n> ### In the first model,\nThe final training accuracy was accuracy: 0.5793, and validation accuracy was val_accuracy: 0.5345. It is a fair model. It probably has overfitting. And the accuracy are consistant.\n\n\n> ### In the second model,\nThe final training accuracy was accuracy: 0.7724, and validation accuracy was val_accuracy: 0.6704. It is good-fit model. It has a nice training curve. However, It shows over-fitting.         \n","metadata":{}},{"cell_type":"code","source":"plt.plot(hist1.history[\"accuracy\"])\nplt.plot(hist1.history['val_accuracy'])\nplt.title(\"Model 1 Evaluation\")\nplt.ylabel(\"Accuracy\")\nplt.xlabel(\"Epoch\")\nplt.legend([\"Training Accuracy\",\"Validation Accuracy\"])\n\nplt.show()\nplt.plot(hist2.history[\"accuracy\"])\nplt.plot(hist2.history['val_accuracy'])\nplt.title(\"Model 2 Evaluation\")\nplt.ylabel(\"Accuracy\")\nplt.xlabel(\"Epoch\")\nplt.legend([\"Training Accuracy\",\"Validation Accuracy\"])\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-27T08:57:04.981063Z","iopub.execute_input":"2023-04-27T08:57:04.981442Z","iopub.status.idle":"2023-04-27T08:57:05.456182Z","shell.execute_reply.started":"2023-04-27T08:57:04.981410Z","shell.execute_reply":"2023-04-27T08:57:05.455111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5. Conclusion \n> ### Comparing two models,\nThe first model performs fair in terms of accuracy. However it is overfitting. After normalized, the second model improved the accuracy, but it is still overfitting\n\n> ### Future Improvement\nIt is suggested to use dropout layer, to solve overfitting. And also consider other RNN technique, such as GRU. Maybe SGD or Adam could be tried as alternative optimization method.","metadata":{}},{"cell_type":"code","source":"#Submission\nimport os\n\ntext_test['wordTotal'] = text_test['clean'].apply(word_count)\ntotal_words_train = max(text_test['wordTotal'])\n\ntokenizer = Tokenizer(num_words = total_words_train)\ntokenizer.fit_on_texts(text_test['clean'])\ntest_sequences = tokenizer.texts_to_sequences(text_test['clean'])\npadded_test = pad_sequences(test_sequences,maxlen = 40, truncating = 'post') \npredictions = model2.predict(padded_test, verbose=1)\nprint(predictions)\npred = np.transpose(predictions)[0]\n\nprint(pred)\n\nsubmission_df = pd.DataFrame()\nsubmission_df['id'] = text_test['id']\nsubmission_df['target'] = list(map(lambda x: 0 if x < 0.5 else 1, pred))\nsubmission_df.to_csv('/kaggle/working/submission.csv', index=False)\nsubmission_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-04-27T09:01:19.790217Z","iopub.execute_input":"2023-04-27T09:01:19.791190Z","iopub.status.idle":"2023-04-27T09:01:20.644353Z","shell.execute_reply.started":"2023-04-27T09:01:19.791135Z","shell.execute_reply":"2023-04-27T09:01:20.643118Z"},"trusted":true},"execution_count":null,"outputs":[]}]}